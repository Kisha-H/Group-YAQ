{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Yudong Chen\n",
    "- Alexander Zhou\n",
    "- Qianxia Hui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "> Does location and average temperature deviation correlate strongly with sentiments about climate change on twitter?\n",
    "\n",
    "We tackle the challenge of uncovering patterns in public sentiments and stances towards climate change, as expressed in a comprehensive dataset of over 15 million tweets collected over 13 years. The problem lies in categorizing these sentiments and stances without predefined labels, necessitating the use of unsupervised learning techniques to identify naturally occurring clusters within the data. This involves quantitatively analyzing tweets to extract features such as sentiment polarity (ranging from negative to positive), stance on climate change (supporting, denying, or neutral), and associating these opinions with demographic (gender) and geographical data (origin of tweets). The core challenge is to transform the subjective, nuanced nature of individual tweets into a structured format that can be analyzed to reveal insights into global public opinion on climate change.\n",
    "\n",
    "Our approach is quantifiable, employing numerical representations of sentiments and leveraging unsupervised clustering algorithms to organize tweets into meaningful groups. This clustering will allow us to measure the distribution of opinions across different demographics and geographies, assess the prominence of certain sentiments, and identify any patterns or trends that emerge from the data. The project is measurable through the application of metrics such as silhouette scores, which evaluate the cohesion and separation of the clusters formed. Replicability is ensured by the dataset's scale and diversity, allowing the methodology and findings to be validated or extended in future research. By addressing this problem, the project aims to provide a granular, data-driven understanding of public sentiment towards climate change, highlighting the role of unsupervised machine learning in extracting actionable insights from unstructured social media data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We will be using the following dataset for our analysis: [link](https://www.kaggle.com/datasets/deffro/the-climate-change-twitter-dataset)\n",
    "\n",
    "In total, the dataset has 15,789,411 rows and 10 columns with each row representing an individual tweet recorded. Of the 10 columns, 8 of them are of interest: lng, lat, topic, sentiment, stance, gender, temperature_avg, and aggressiveness. \n",
    "The lng and lat columns are continuous values that record the geographical location of the tweet, i.e. where the user is from. The topic column categorizes the tweet into one of ten semantic categories based on clustering by an LDA algorithm. The sentiment column rates the negative and positive sentiment of the tweet on a scale from -1 to 1 with 0 being neutral. The stance column indicates whether the tweet supports, rejects, or is neutral towards man-made climate change. The temperature_avg column records the deviation of temperature in celsius at the location the tweet was made in compared to the 1951 to 1980 average temperature. Finally, aggressiveness is a binary column that indicates whether the tweet contains aggressive language or not. \n",
    "\n",
    "As the data currently stands, a majority of the data is missing in the lng and lat columns. While we can try to impute the missing values, simply dropping null rows will still leave 5,307,538 rows in the dataset that we can use. The other columns are not as unfilled, and it should be fine to either impute the missing values or drop null rows as needed. \n",
    "\n",
    "For the purposes of doing clustering analysis on the dataset, we will also want to standard scale all the numerical variables and one-hot encode all the categorical variables. Otherwise the data is fairly robust and maintained. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We propose to use unsupervised clustering models such as K-means, Gaussian Mixture, and hierarchical models to identify unique clusters of tweets within the dataset using existing variables that measure the sentiment, semantics, location, and more about the tweet. Then, by analyzing the stance of the clusters to see if any clusters are particularly in belief or disbelief of climate change, we will hopefully be able to identify characteristics of the demographic that correlate or relate to their belief in man-made climate change.\n",
    "\n",
    "Specifically, we plan to utilize the sci-kit learn library to first preprocess the data using pipelines, encoders, scalers, and more. We will separate out the stance column and treat it as our final Y variable. Then, once the data has been standardized and cleaned, we will use the library’s various clustering model implementations in order to test various methods of clustering and see whether specific clusters are good predictors of stance on climate change. If a specific cluster is largely in belief of climate change for example, we can then isolate and analyze the cluster to see what makes it unique. For example, users from a particular country may believe more in climate change than users from other countries. We can also use dimensionality reduction methods such as PCA to visualize the clusters in a graph to aid in exploratory analysis. \n",
    "\n",
    "Once we have identified certain hypotheses from the clustering analysis, we can then test them statistically to confirm the validity of the hypothesized relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Since we have the true labels, namely the stance of the user behind the tweet, we can use that as the ground truth clustering to compare against the results from our own clustering. This can be evaluated using metrics such as the rand and adjusted rand index that measure how similar the clusterings are in terms of how many pairings agree with each other compared to all possible pairings. The adjusted rand index accounts for random chance clustering as a baseline for the expected score. If the data is convex, we can also use other metrics such as the silhouette score, which compares the mean distance between points to their cluster’s mean and the mean distance between points to the nearest other cluster’s mean, to measure cluster quality. These measures will help us determine how well the clustering aligns with the true labels and whether they can be utilized to identify demographics that relate to belief in climate change.  \n",
    "\n",
    "Once we have identified predictor variables for stance on climate change, we can then utilize statistical tests like the t-test or analysis libraries like statsmodels and more to evaluate the relationship between the variables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integration of machine learning (ML) in analyzing social media datasets, especially on sensitive topics as significant as climate change, necessitates a rigorous ethical and privacy framework. Our dataset “Climate Change Twitter Dataset” from Kaggle presents both an opportunity for insightful analysis and responsibility to address potential ethical and privacy concerns. In this section, we will outline our commitment to ethical research practices and privacy preservation, addressing our potential concerns and the proactive actions we are going to take.\n",
    "\n",
    "We will protect privacy and anonymity for every individual in our dataset. Though the data from Twitter is public, the dataset contains geolocation and gender information that may lead to identification of individuals. This raises concerns about the privacy of the individuals whose data are included in the dataset. We will adhere strictly to anonymizing any data used in our analysis and use geolocation data cautiously to ensure individuals cannot be identified through tweets locations. In addition, the hydrating process of tweets will be conducted with the awareness of Twitter’s privacy policy and our aim to prevent unauthorized disclosure of user information.\n",
    "\n",
    "Due to the comprehensive nature of the twitter dataset including sentiment analysis on climate change, it poses risks of misinterpretation and misuse. We will implement rigorous data interpretation guidelines to ensure that our analysis respects the complexity of human opinions and avoids misrepresentation.\n",
    "\n",
    "In order to avoid potential bias within our dataset, the diverse methodologies used to generate the dataset (e.g., BERT, LSTM, CNN) are not immune to biases present in the underlying data or in the algorithms themselves. We commit to actively seeking out and mitigating these biases, ensuring our analysis promotes fairness and accuracy. Our team will conduct regular reviews of our models and methodologies to identify and correct for biases, ensuring our work contributes positively to the discourse around climate change and social media analysis. Tools like Deon will be used to systematically address ethical issues throughout the project lifecycle. This includes careful consideration of the ethical implications of data collection, analysis, and dissemination. \n",
    "\n",
    "We acknowledge that there may be unintended consequences as a result of our data analysis. We will take special care to avoid any analysis that could be used to target or discriminate against individuals based on their opinions, gender, nationalities, or any other attribute. Furthermore, while Twitter is a public platform, the users' informed consent for this specific form of data analysis and aggregation might not have been obtained. Our project will acknowledge this limitation and the ethical implications of using publicly available data for research purposes, citing the original papers as required and providing transparency about our research intentions and methods.\n",
    "\n",
    "We are committed to transparency in our research and will offer both a summary and comprehensive details of the procedures we undertake in our analysis, along with any issues that might emerge during this process. The main objective of our project is to enhance public and environmental safety and reduce any possible negative impacts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Communication\n",
    "- Weekly Meetings:  The team will meet weekly at a mutually agreed upon time.\n",
    "- Primary Platform: Team communication will be conducted via Discord, including updates, questions, and general discussions related to the project.\n",
    "- Github Coordination: When making changes to the project on Github, members must post a brief update in the team Discord group to keep everyone informed.\n",
    "- Openness: Encourage an atmosphere where each member feels comfortable sharing ideas, questions, and concerns. All communication must be respectful.\n",
    "2. Contributions\n",
    "- Equitable Contribution: Each member is expected to contribute equally to the project. Workload distribution will be reviewed regularly to ensure fairness.\n",
    "- Accountability: Every member is responsible for completing their assigned tasks by the agreed deadlines.\n",
    "3. Conflict and Difficulty\n",
    "- Support: If a member encounters difficulties with their portion of the project, they are encouraged to seek assistance from other team members sooner rather than later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>\n",
    "            Meeting Date\n",
    "        </th>\n",
    "        <th>\n",
    "            Meeting Time\n",
    "        </th>\n",
    "        <th>\n",
    "            Completed before meeting\n",
    "        </th>\n",
    "        <th>\n",
    "            Discuss at meeting\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            2/13\n",
    "        </td>\n",
    "        <td>\n",
    "            3pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Brainstorm topics / questions (all)\n",
    "        </td>\n",
    "        <td>\n",
    "            Use Discord for communication; Discussed and decided our final project topic; distributed work for each member; decided time for next meeting\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            2/19\n",
    "        </td>\n",
    "        <td>\n",
    "            8pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Proposal review\n",
    "        </td>\n",
    "        <td>\n",
    "            Review draft project proposal; Decide next meeting time\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            2/26\n",
    "        </td>\n",
    "        <td>\n",
    "            8pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Research EDA methods\n",
    "        </td>\n",
    "        <td>\n",
    "            Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            3/4\n",
    "        </td>\n",
    "        <td>\n",
    "            8pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Finish EDA\n",
    "        </td>\n",
    "        <td>\n",
    "            Discuss final project writeup; assign individual tasks\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            3/11\n",
    "        </td>\n",
    "        <td>\n",
    "            8pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Finish project\n",
    "        </td>\n",
    "        <td>\n",
    "            Revise/catch up on remaining work that needs to be done\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            3/18\n",
    "        </td>\n",
    "        <td>\n",
    "            8pm\n",
    "        </td>\n",
    "        <td>\n",
    "            Final Project Review\n",
    "        </td>\n",
    "        <td>\n",
    "            Review and Turn in Final Project\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
